{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ονοματεπώνυμο και ΑΜ\n",
    "# Παντελεήμων Μαλέκας 1115201600268"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing and cleanup of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "\n",
    "#In this part we will take each file and make the necessary changes to our data.\n",
    "\n",
    "train_path = r'C:\\Users\\Pantelis\\Documents\\uni\\tede\\Third\\data\\train.csv'\n",
    "\n",
    "#First we will convert every uppercase character to lowercase using the str.lower() function.\n",
    "train_data = pd.read_csv(train_path, dtype=str).apply(lambda x: x.astype(str).str.lower())\n",
    "\n",
    "#Now we will remove certain characters with the sub() function provided by the re module.\n",
    "\n",
    "#We will substitute every unwanted character with ' '. Here we remove the URLs.\n",
    "train_data['Comment'] = train_data['Comment'].apply(lambda y: re.sub(r'(https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b', \" \", y , flags=re.MULTILINE) )\n",
    "\n",
    "#Here we remove escape characters such as \\n, \\x and \\u.\n",
    "train_data['Comment'] = train_data['Comment'].apply(lambda z: re.sub(r'\\\\n', \" \", z , flags=re.MULTILINE) )\n",
    "train_data['Comment'] = train_data['Comment'].apply(lambda z: re.sub(r'\\\\x..', \" \", z , flags=re.MULTILINE) )\n",
    "train_data['Comment'] = train_data['Comment'].apply(lambda z: re.sub(r'\\\\u....', \" \", z , flags=re.MULTILINE) )\n",
    "\n",
    "#And finally we remove any other remaining symbols by removing every non-alphabetic character.\n",
    "train_data['Comment'] = train_data['Comment'].apply(lambda k: re.sub(\"[^a-z]+\", \" \", k, flags=re.MULTILINE) )\n",
    "\n",
    "#Similar work performed in the 'impermium_verification_set' file.\n",
    "test_path = r'C:\\Users\\Pantelis\\Documents\\uni\\tede\\Third\\data\\impermium_verification_set.csv'\n",
    "test_data = pd.read_csv(test_path, dtype=str).apply(lambda x: x.astype(str).str.lower())\n",
    "\n",
    "test_data['Comment'] = test_data['Comment'].apply(lambda y: re.sub(r'(https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b', \" \", y , flags=re.MULTILINE) )\n",
    "\n",
    "test_data['Comment'] = test_data['Comment'].apply(lambda z: re.sub(r'\\\\n', \" \", z , flags=re.MULTILINE) )\n",
    "test_data['Comment'] = test_data['Comment'].apply(lambda z: re.sub(r'\\\\x..', \" \", z , flags=re.MULTILINE) )\n",
    "test_data['Comment'] = test_data['Comment'].apply(lambda z: re.sub(r'\\\\u....', \" \", z , flags=re.MULTILINE) )\n",
    "\n",
    "test_data['Comment'] = test_data['Comment'].apply(lambda k: re.sub(\"[^a-z]+\", \" \", k, flags=re.MULTILINE) )\n",
    "\n",
    "#Similar work performed in the 'impermium_verification_labels' file.\n",
    "test_path_labels = r'C:\\Users\\Pantelis\\Documents\\uni\\tede\\Third\\data\\impermium_verification_labels.csv'\n",
    "test_labels = pd.read_csv(test_path_labels, dtype=str).apply(lambda x: x.astype(str).str.lower())\n",
    "\n",
    "test_labels['Comment'] = test_labels['Comment'].apply(lambda y: re.sub(r'(https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b', \"\", y , flags=re.MULTILINE) )\n",
    "\n",
    "test_labels['Comment'] = test_labels['Comment'].apply(lambda z: re.sub(r'\\\\n', \" \", z , flags=re.MULTILINE) )\n",
    "test_labels['Comment'] = test_labels['Comment'].apply(lambda z: re.sub(r'\\\\x..', \" \", z , flags=re.MULTILINE) )\n",
    "test_labels['Comment'] = test_labels['Comment'].apply(lambda z: re.sub(r'\\\\u....', \" \", z , flags=re.MULTILINE) )\n",
    "\n",
    "test_labels['Comment'] = test_labels['Comment'].apply(lambda k: re.sub(\"[^a-z]+\", \" \", k, flags=re.MULTILINE) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes classification with CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification scores for Naive Bayes and its enhancements.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classification Method</th>\n",
       "      <th>Classification Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.674720</td>\n",
       "      <td>0.674774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NB with Lemmatization</td>\n",
       "      <td>0.676063</td>\n",
       "      <td>0.676087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NB without Stop Words</td>\n",
       "      <td>0.688143</td>\n",
       "      <td>0.682593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NB with Bigrams</td>\n",
       "      <td>0.665324</td>\n",
       "      <td>0.657340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NB with Laplace Smoothing</td>\n",
       "      <td>0.682774</td>\n",
       "      <td>0.678859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Classification Method  Classification Accuracy  F1 Score\n",
       "0                Naive Bayes                 0.674720  0.674774\n",
       "1      NB with Lemmatization                 0.676063  0.676087\n",
       "2      NB without Stop Words                 0.688143  0.682593\n",
       "3            NB with Bigrams                 0.665324  0.657340\n",
       "4  NB with Laplace Smoothing                 0.682774  0.678859"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import naive_bayes\n",
    "\n",
    "import nltk\n",
    "\n",
    "#Now we will classify our data with the Naive Bayes classifier.\n",
    "\n",
    "\n",
    "#Encoding the labels we have.\n",
    "Encoder = LabelEncoder() \n",
    "Train_Y = Encoder.fit_transform(train_data[\"Insult\"])\n",
    "Test_Y = Encoder.fit_transform(test_labels[\"Insult\"])\n",
    "\n",
    "#Using the CountVectorizer to fit and transform our data.\n",
    "count_vectorizer = CountVectorizer()\n",
    "counts_train = count_vectorizer.fit_transform(train_data['Comment'])\n",
    "counts_test = count_vectorizer.transform(test_data['Comment'])\n",
    "\n",
    "#Initializing the NB object. Alpha here is set to 0.5. The default value is 1.0 which is also the one used for Laplace Smoothing.\n",
    "#By setting alpha to 0.5 we will be using Lidstone Smoothing in order to see the necessary changes when it will be later set to 1.0\n",
    "Bayes = naive_bayes.MultinomialNB(alpha = 0.5)\n",
    "\n",
    "#Fitting the training data and making predictions on the test set.\n",
    "Bayes.fit(counts_train,Train_Y)\n",
    "predictions_Bayes = Bayes.predict(counts_test)\n",
    "\n",
    "#Getting the scores we need.\n",
    "acc_score_test = accuracy_score(Test_Y, predictions_Bayes)\n",
    "f1_score_test = f1_score(Test_Y, predictions_Bayes, average = 'weighted')\n",
    "\n",
    "\n",
    "#Now we will check the required enhancements to our classification method.\n",
    "\n",
    "#First we will perform lemmatization in our text. The required objects are initialized here.\n",
    "tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "#Defining a lemmatize function that will lemmatize our text and return it in string format.\n",
    "def lemmatize(text):\n",
    "    string_list = [lemmatizer.lemmatize(word) for word in tokenizer.tokenize(text)]\n",
    "    list_to_str = ' '.join([str(element) for element in string_list])\n",
    "    return list_to_str\n",
    "\n",
    "#Performing lemmatization in our texts.\n",
    "train_data['lemmatized_comment'] = train_data.Comment.apply(lemmatize)\n",
    "test_data['lemmatized_comment'] = test_data.Comment.apply(lemmatize)\n",
    "\n",
    "#Performing Naive Bayes Classification. Same as before, but now using the 'lemmatized_comment' column.\n",
    "count_vectorizer_1 = CountVectorizer()\n",
    "counts_train_1 = count_vectorizer_1.fit_transform(train_data['lemmatized_comment'])\n",
    "counts_test_1 = count_vectorizer_1.transform(test_data['lemmatized_comment'])\n",
    "\n",
    "Bayes_1 = naive_bayes.MultinomialNB(alpha = 0.5)\n",
    "Bayes_1.fit(counts_train_1,Train_Y)\n",
    "predictions_Bayes_1 = Bayes_1.predict(counts_test_1)\n",
    "\n",
    "acc_score_test1 = accuracy_score(Test_Y, predictions_Bayes_1)\n",
    "f1_score_test1 = f1_score(Test_Y, predictions_Bayes_1, average = 'weighted')\n",
    "\n",
    "\n",
    "\n",
    "#For the next enhancement, we will remove stop words. Everything else is done same as in the previous cases.\n",
    "count_vectorizer_2 = CountVectorizer(stop_words = 'english')\n",
    "counts_train_2 = count_vectorizer_2.fit_transform(train_data['Comment'])\n",
    "counts_test_2 = count_vectorizer_2.transform(test_data['Comment'])\n",
    "\n",
    "Bayes_2 = naive_bayes.MultinomialNB(alpha = 0.5)\n",
    "Bayes_2.fit(counts_train_2,Train_Y)\n",
    "predictions_Bayes_2 = Bayes_2.predict(counts_test_2)\n",
    "\n",
    "acc_score_test2 = accuracy_score(Test_Y, predictions_Bayes_2)\n",
    "f1_score_test2 = f1_score(Test_Y, predictions_Bayes_2, average = 'weighted')\n",
    "\n",
    "\n",
    "\n",
    "#For the next enhancement, we will be using bigrams instead of unigrams. Everything else is done same as in the previous cases.\n",
    "count_vectorizer_3 = CountVectorizer(ngram_range=(2,2))\n",
    "counts_train_3 = count_vectorizer_3.fit_transform(train_data['Comment'])\n",
    "counts_test_3 = count_vectorizer_3.transform(test_data['Comment'])\n",
    "\n",
    "Bayes_3 = naive_bayes.MultinomialNB(alpha = 0.5)\n",
    "Bayes_3.fit(counts_train_3,Train_Y)\n",
    "predictions_Bayes_3 = Bayes_3.predict(counts_test_3)\n",
    "\n",
    "acc_score_test3 = accuracy_score(Test_Y, predictions_Bayes_3)\n",
    "f1_score_test3 = f1_score(Test_Y, predictions_Bayes_3, average = 'weighted')\n",
    "\n",
    "\n",
    "\n",
    "#For the next enhancement, we will be using Laplace Smoothing. This is done by setting the aplha value to 1.0. Everything else is done same as in the previous cases.\n",
    "Bayes_4 = naive_bayes.MultinomialNB(alpha = 1.0)\n",
    "Bayes_4.fit(counts_train,Train_Y)\n",
    "predictions_Bayes_4 = Bayes_4.predict(counts_test)\n",
    "\n",
    "acc_score_test4 = accuracy_score(Test_Y, predictions_Bayes_4)\n",
    "f1_score_test4 = f1_score(Test_Y, predictions_Bayes_4, average = 'weighted')\n",
    "\n",
    "#Now we will create a dataframe that will keep our scores. \n",
    "bayes_df = pd.DataFrame(columns=['Classification Method', 'Classification Accuracy', 'F1 Score'])\n",
    "bayes_df = bayes_df.append({'Classification Method': 'Naive Bayes', 'Classification Accuracy':acc_score_test, 'F1 Score': f1_score_test}, ignore_index=True)\n",
    "bayes_df = bayes_df.append({'Classification Method': 'NB with Lemmatization', 'Classification Accuracy':acc_score_test1, 'F1 Score': f1_score_test1}, ignore_index=True)\n",
    "bayes_df = bayes_df.append({'Classification Method': 'NB without Stop Words', 'Classification Accuracy':acc_score_test2, 'F1 Score': f1_score_test2}, ignore_index=True)\n",
    "bayes_df = bayes_df.append({'Classification Method': 'NB with Bigrams', 'Classification Accuracy':acc_score_test3, 'F1 Score': f1_score_test3}, ignore_index=True)\n",
    "bayes_df = bayes_df.append({'Classification Method': 'NB with Laplace Smoothing', 'Classification Accuracy':acc_score_test4, 'F1 Score': f1_score_test4}, ignore_index=True)\n",
    "\n",
    "#Printing our scores.\n",
    "print(\"Classification scores for Naive Bayes and its enhancements.\")\n",
    "bayes_df\n",
    "\n",
    "#Conclusions and Notes:\n",
    "#As we can see, the Naive Bayes algorithm gives some average scores. Each enhancement gave slightly better results.\n",
    "\n",
    "#Lemmatization made a slight improvement. \n",
    "#This is expected given that lemmatization reduces the tokens we have (by for example transforming 'uses' and 'used' to 'use').\n",
    "#This allows for Naive Bayes to make better predictions.\n",
    "\n",
    "#The removal of stop words also improved our results.\n",
    "#By giving the algorithm more important words to work on, this allowed for better predictions.\n",
    "\n",
    "#Bigrams reduced our scores. Actually, this is expected. The use of bigrams significantly reduces the range of the words we have.\n",
    "#Since the predictions are way less we are expected to have reduced scores. \n",
    "#I should note here that if one wishes to add unigrams along with bigrams the scores will change.\n",
    "#Classifying unigrams along with bigrams gives more accurate scores (about the same results as in the ones that use lemmatization).\n",
    "\n",
    "#The use of Laplace smoothing also increased our scores. Since Laplace smoothing eliminates cases of zero probability this allowed for higher accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the TF-IDF and POS array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Getting the POS tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will create the desired array, by getting the POS tags first.\n",
    "\n",
    "#We will create two dataframes that will keep the fraction of each POS tag.\n",
    "fraction_df = pd.DataFrame(columns=['fractionAdverbs', 'fractionVerbs', 'fractionNouns', 'fractionAdjectives'])\n",
    "fraction_test = pd.DataFrame(columns=['fractionAdverbs', 'fractionVerbs', 'fractionNouns', 'fractionAdjectives'])\n",
    "\n",
    "#Getting the only the Date and Comment columns from our previous dataframes.\n",
    "train_df2 = train_data[ ['Date','Comment'] ]\n",
    "test_df2 = test_data[ ['Date','Comment'] ]\n",
    "\n",
    "#Iterating every comment and getting the POS tags.\n",
    "for index, row in train_df2.iterrows():\n",
    "    \n",
    "    #Tokenizing the comment and getting the tags. I decided to use the universal tagset to get simplified tags.\n",
    "    tokens = nltk.word_tokenize(row['Comment'])\n",
    "    tag_list = nltk.pos_tag(tokens,tagset='universal')\n",
    "    tag_len = len(tag_list)\n",
    "    \n",
    "    #Counting the tags.\n",
    "    noun_count = 0\n",
    "    verb_count = 0\n",
    "    adv_count = 0\n",
    "    adj_count = 0\n",
    "    for i,j in tag_list:\n",
    "        if j == 'NOUN':\n",
    "            noun_count = noun_count + 1\n",
    "        if j == 'VERB':\n",
    "            verb_count = verb_count + 1\n",
    "        if j == 'ADV':\n",
    "            adv_count = adv_count + 1\n",
    "        if j == 'ADJ':\n",
    "            adj_count = adj_count + 1\n",
    "        \n",
    "    #Getting the frequencies.\n",
    "    noun_freq = 0.0\n",
    "    verb_freq = 0.0\n",
    "    adv_freq = 0.0\n",
    "    adj_freq = 0.0\n",
    "    if tag_len != 0 :\n",
    "        noun_freq = noun_count / tag_len\n",
    "        verb_freq = verb_count / tag_len\n",
    "        adv_freq = adv_count / tag_len\n",
    "        adj_freq = adj_count / tag_len\n",
    "    \n",
    "    #Adding the fractions to the fraction dataframe.    \n",
    "    fraction_df = fraction_df.append({'fractionAdverbs': adv_freq, 'fractionVerbs': verb_freq, 'fractionNouns': noun_freq, 'fractionAdjectives': adj_freq }, ignore_index=True)\n",
    "    \n",
    "#Similar work performed for the test dataset.\n",
    "for index, row in test_df2.iterrows():\n",
    "    tokens = nltk.word_tokenize(row['Comment'])\n",
    "    tag_list = nltk.pos_tag(tokens,tagset='universal')\n",
    "    tag_len = len(tag_list)\n",
    "    \n",
    "    noun_count = 0\n",
    "    verb_count = 0\n",
    "    adv_count = 0\n",
    "    adj_count = 0\n",
    "    for i,j in tag_list:\n",
    "        if j == 'NOUN':\n",
    "            noun_count = noun_count + 1\n",
    "        if j == 'VERB':\n",
    "            verb_count = verb_count + 1\n",
    "        if j == 'ADV':\n",
    "            adv_count = adv_count + 1\n",
    "        if j == 'ADJ':\n",
    "            adj_count = adj_count + 1\n",
    "        \n",
    "    noun_freq = 0.0\n",
    "    verb_freq = 0.0\n",
    "    adv_freq = 0.0\n",
    "    adj_freq = 0.0\n",
    "    if tag_len != 0 :\n",
    "        noun_freq = noun_count / tag_len\n",
    "        verb_freq = verb_count / tag_len\n",
    "        adv_freq = adv_count / tag_len\n",
    "        adj_freq = adj_count / tag_len\n",
    "    \n",
    "        \n",
    "    fraction_test = fraction_test.append({'fractionAdverbs': adv_freq, 'fractionVerbs': verb_freq, 'fractionNouns': noun_freq, 'fractionAdjectives': adj_freq }, ignore_index=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Merging the TF-IDF array and the POS tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#We continue by concatinating the original dataframes with the ones that contain the fractions.\n",
    "train1 = pd.concat([train_data, fraction_df], axis = 1)\n",
    "test1 = pd.concat([test_data, fraction_test], axis = 1)\n",
    "\n",
    "#Getting the fractions in list format.\n",
    "fractionAdverbs = train1['fractionAdverbs'].tolist()\n",
    "fractionVerbs = train1['fractionVerbs'].tolist()\n",
    "fractionNouns = train1['fractionNouns'].tolist()\n",
    "fractionAdjectives = train1['fractionAdjectives'].tolist()\n",
    "\n",
    "#Same for the test dataset.\n",
    "fractionAdverbs_test = test1['fractionAdverbs'].tolist()\n",
    "fractionVerbs_test = test1['fractionVerbs'].tolist()\n",
    "fractionNouns_test = test1['fractionNouns'].tolist()\n",
    "fractionAdjectives_test = test1['fractionAdjectives'].tolist()\n",
    "\n",
    "#Initializing the TF-IDF vectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "tfs_train = tfidf.fit_transform(train1['Comment'])\n",
    "tfs_test = tfidf.transform(test1['Comment'])\n",
    "\n",
    "#Getting the TF-IDF array in dense format so we can merge it with the fractions.\n",
    "dense = tfs_train.todense()\n",
    "dense_test = tfs_test.todense()\n",
    "\n",
    "#Zipping all the fractions.\n",
    "all_fracs = list(zip(fractionAdverbs, fractionVerbs, fractionNouns,fractionAdjectives ))\n",
    "all_fracs_test = list(zip(fractionAdverbs_test, fractionVerbs_test, fractionNouns_test,fractionAdjectives_test ))\n",
    "\n",
    "#Merging the TF-IDF array with the fraction arrays.\n",
    "tf_pos = np.append(dense, all_fracs, 1)\n",
    "tf_pos_test = np.append(dense_test, all_fracs_test, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Classification with SVM and Random Forests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification scores for SVM and Random Forests on the TF-IDF/POS array.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classification Method</th>\n",
       "      <th>Classification Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.680089</td>\n",
       "      <td>0.654029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.634004</td>\n",
       "      <td>0.581631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classification Method  Classification Accuracy  F1 Score\n",
       "0                   SVM                 0.680089  0.654029\n",
       "1         Random Forest                 0.634004  0.581631"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initializing the SVM object.\n",
    "SVM = svm.SVC()\n",
    "\n",
    "#Fitting the training data and making predictions on the test.\n",
    "SVM.fit(tf_pos,Train_Y)\n",
    "predictions_SVM = SVM.predict(tf_pos_test)\n",
    "\n",
    "#Getting the scores we need.\n",
    "acc_score_test = accuracy_score(Test_Y, predictions_SVM)\n",
    "f1_score_test = f1_score(Test_Y, predictions_SVM, average = 'weighted')\n",
    "\n",
    "\n",
    "#Initializing the Random Forest object.\n",
    "RF = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Fitting the training data and making predictions on the test.\n",
    "RF.fit(tf_pos,Train_Y)\n",
    "predictions_RF = RF.predict(tf_pos_test)\n",
    "\n",
    "#Getting the scores we need.\n",
    "acc_score_test1 = accuracy_score(Test_Y, predictions_RF)\n",
    "f1_score_test1 = f1_score(Test_Y, predictions_RF, average = 'weighted')\n",
    "\n",
    "\n",
    "#Using a dataframe to print our results.\n",
    "tf_pos_df = pd.DataFrame(columns=['Classification Method', 'Classification Accuracy', 'F1 Score'])\n",
    "tf_pos_df = tf_pos_df.append({'Classification Method': 'SVM', 'Classification Accuracy':acc_score_test, 'F1 Score': f1_score_test}, ignore_index=True)\n",
    "tf_pos_df = tf_pos_df.append({'Classification Method': 'Random Forest', 'Classification Accuracy':acc_score_test1, 'F1 Score': f1_score_test1}, ignore_index=True)\n",
    "\n",
    "print(\"Classification scores for SVM and Random Forests on the TF-IDF/POS array.\")\n",
    "tf_pos_df\n",
    "\n",
    "#Conclusions and Notes:\n",
    "#The TF-IDF/POS representation proved to be a entirely different model than the one used in CountVectorizer.\n",
    "\n",
    "#In SVM we see that the scores were about the same, if not a bit higher than the ones we got in Naive Bayes. \n",
    "#This is expected given that SVM uses binary classification. For this reason, it was able to achieve quite accurate scores (since our labels are also binary).\n",
    "\n",
    "#In Random Forest we see that the scores are less accurate than the ones we got in Naive Bayes.\n",
    "#There is also random chance taken in account in this algorithm so the results may vary a bit in different executions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beating the benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification scores for my attempt on beating the benchmark.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classification Method</th>\n",
       "      <th>Classification Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest with additions</td>\n",
       "      <td>0.702461</td>\n",
       "      <td>0.688464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Classification Method  Classification Accuracy  F1 Score\n",
       "0  Random Forest with additions                 0.702461  0.688464"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Decided to use CountVectorizer since it provided better scores than either TF-IDF or TF-IDF/POS representations.\n",
    "#By removing the stop words and using the lemmatized comments, we get more accurate results.\n",
    "count_vectorizer_f = CountVectorizer(stop_words = 'english')\n",
    "counts_train_f = count_vectorizer_f.fit_transform(train_data['lemmatized_comment'])\n",
    "counts_test_f = count_vectorizer_f.transform(test_data['lemmatized_comment'])\n",
    "\n",
    "#Random Forest Classifier provided the most accurate results so far.\n",
    "RF.fit(counts_train_f,Train_Y)\n",
    "predictions_RF = RF.predict(counts_test_f)\n",
    "\n",
    "#Getting our scores.\n",
    "acc_score_test = accuracy_score(Test_Y, predictions_RF)\n",
    "f1_score_test = f1_score(Test_Y, predictions_RF, average = 'weighted')\n",
    "\n",
    "#Using a dataframe to print them.\n",
    "final_df = pd.DataFrame(columns=['Classification Method', 'Classification Accuracy', 'F1 Score'])\n",
    "final_df = final_df.append({'Classification Method': 'Random Forest with additions', 'Classification Accuracy':acc_score_test, 'F1 Score': f1_score_test}, ignore_index=True)\n",
    "\n",
    "print(\"Classification scores for my attempt on beating the benchmark.\")\n",
    "final_df\n",
    "\n",
    "#Conclusions and Notes:\n",
    "#Here I decided to merge the different techniques we explored in the previous questions. \n",
    "#The lemmatized comments and the removal of stop words proved to be highly accurate. Bigrams didn't achieve higher accuracy.\n",
    "\n",
    "#Regarding the classifiers, Random Forest gave the best results. \n",
    "#Since random chance is taken in account in this algorithm, the results may vary a bit in different executions.\n",
    "#All of the ones I tried however were about 0.69 to 0.70.\n",
    "\n",
    "#Since Random Forest gives a bit random results, I also tried classifying with Naive Bayes to see more stable results.\n",
    "#Naive Bayes with alpha set to 0.6 also gave some quite accurate results of about 0.6908.\n",
    "#SVM gave the least accurate scores of the three algorithms, so it was discarded."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
